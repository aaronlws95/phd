{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aaron/anaconda3/envs/tf_cu9/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "CAM_INTR_COLOR = K.constant([[1395.749023, 0, 935.732544],\n",
    "                            [0, 1395.749268, 540.681030],\n",
    "                            [0, 0, 1]])\n",
    "\n",
    "skel_xyz = tf.Variable(np.ones((21, 3), dtype=np.float32))\n",
    "pred_offset = tf.Variable(np.ones((21, 3), dtype=np.float32))\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "# print(CAM_INTR_COLOR[1:, :])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    skel_xyz_intr = K.transpose(K.dot(CAM_INTR_COLOR, K.transpose(skel_xyz)))\n",
    "#     print(tf.math.divide(skel_xyz_intr[:, 0],skel_xyz_intr[:, 2])\n",
    "    skel_uvd = tf.stack([skel_xyz_intr[:, 0]/skel_xyz_intr[:, 2], \n",
    "                         skel_xyz_intr[:, 1]/skel_xyz_intr[:, 2], \n",
    "                         skel_xyz_intr[:, 2]], \n",
    "                         axis = 1)\n",
    "#     print(skel_uvd)\n",
    "#     print(pred_offset)\n",
    "#     print(pred_offset[0, :])\n",
    "    pred_hand_pose_root = tf.expand_dims(tf.stack([pred_offset[0, 0], pred_offset[0, 1]+1, pred_offset[0, 2]+2]), 0)\n",
    "    pred_hand_pose_rest = tf.map_fn(lambda x: [x[0], x[1]+1, x[2]+2], tf.unstack(pred_offset[1:, :], axis=1))\n",
    "#     print(pred_hand_pose_root)\n",
    "    pred_hand_pose_rest_test = K.transpose(tf.stack(pred_hand_pose_rest))\n",
    "    print(pred_hand_pose_rest_test.eval())\n",
    "#     pred_hand_pose = tf.concat([pred_hand_pose_root, pred_hand_pose_rest], axis=0)\n",
    "#     print(pred_hand_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [ 0  0  1]\n",
      " [ 0  0  2]\n",
      " ...\n",
      " [12 12  2]\n",
      " [12 12  3]\n",
      " [12 12  4]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    index = K.arange(845)\n",
    "    unravel_index = K.transpose(tf.unravel_index(index, (13, 13, 5)))\n",
    "    print(unravel_index.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hpluso_loss(y_gt, y_pred):\n",
    "#     # y_pred = K.reshape(y_pred, (-1, W, H, D, 64))\n",
    "#     conf_loss = 0\n",
    "#     hpe_loss = K.zeros([1])\n",
    "#     # convert to image space\n",
    "#     # y_uvd_gt = camcoord2uvd(y_gt)\n",
    "\n",
    "#     # min_u = K.min(y_uvd_gt[:, 0])\n",
    "#     # max_u = K.max(y_uvd_gt[:, 0])\n",
    "#     # min_v = K.min(y_uvd_gt[:, 1])\n",
    "#     # max_v = K.max(y_uvd_gt[:, 1])\n",
    "#     # min_z = K.min(y_uvd_gt[:, 2])\n",
    "#     # max_z = K.max(y_uvd_gt[:, 2])\n",
    "#     # hand_cell_range_u = list(range(int(min_u/C_u), tf.math.ceil(max_u/C_u)))\n",
    "#     # hand_cell_range_v = list(range(int(min_v/C_v), tf.math.ceil(max_v/C_v)))\n",
    "#     # hand_cell_range_z = list(range(int(min_z/C_z), tf.math.ceil(max_z/C_z)))\n",
    "\n",
    "#     # for u in range(0, W):\n",
    "#     #     for v in range(0, H):\n",
    "#     #         for z in range(0, D):\n",
    "\n",
    "#     #             #hand pose\n",
    "#     #             pred_offset = y_pred[u, v, z, :63]\n",
    "#     #             pred_offset = K.reshape(pred_offset, (21,3))\n",
    "#     #             pred_hand_pose = K.zeros(pred_offset.shape)\n",
    "\n",
    "#     #             pred_hand_pose_root = tf.expand_dims(tf.stack([ K.sigmoid(pred_offset[0, 0])+u,  K.sigmoid(pred_offset[0, 1])+v,  K.sigmoid(pred_offset[0, 2])+z]), 0)\n",
    "#     #             pred_hand_pose_rest = tf.map_fn(lambda x: tf.stack([x[0]+u, x[1]+v, x[2]+z])+z, pred_offset[1:, :])\n",
    "#     #             pred_hand_pose = tf.concat([pred_hand_pose_root, pred_hand_pose_rest], axis=0)\n",
    "\n",
    "#     #             # #confidence\n",
    "#     #             # print(pred_hand_pose[:, :2])\n",
    "#     #             # print(y_gt)\n",
    "#     #             # print(y_uvd_gt[:, :2])\n",
    "#     #             # DT_uv = l2_dist(pred_hand_pose[:, :2], y_uvd_gt[:, :2])\n",
    "#     #             # if DT_uv < d_th:\n",
    "#     #             #     conf_uv = K.exp(a*(1-(DT_uv/d_th)))\n",
    "#     #             # else:\n",
    "#     #             #     conf_uv = 0\n",
    "#     #             # DT_z = l2_dist(pred_hand_pose[:, 2], skel_uvd_gt[:, 2])\n",
    "#     #             # if DT_z < d_th:\n",
    "#     #             #     conf_z = K.exp(a*(1-(DT_z/d_th)))\n",
    "#     #             # else:\n",
    "#     #             #     conf_z = 0\n",
    "#     #             # conf = 0.5*conf_uv + 0.5*conf_z\n",
    "\n",
    "#     #             #calc loss\n",
    "#     #             # pred_hand_pose[:, 0] = C_u*pred_hand_pose[:, 0]\n",
    "#     #             # pred_hand_pose[:, 1] = C_v*pred_hand_pose[:, 1]\n",
    "#     #             # pred_hand_pose[:, :2] = C_z*pred_hand_pose[:, :2]*pred_hand_pose[:, 2:]\n",
    "#     #             # pred_poses_xyz = K.transpose(K.dot(INV_CAM_INTR_COLOR, K.transpose(pred_hand_pose)))\n",
    "#     #             # print(pred_poses_xyz)\n",
    "#     #             # # conf_loss += l2_dist(y_pred[u, v, z, 63], conf)\n",
    "#     #             # hpe_loss += l2_dist(pred_poses_xyz, y_gt)\n",
    "\n",
    "#     return hpe_loss\n",
    "\n",
    "\n",
    "# def camcoord2uvd(skel_xyz):\n",
    "#     skel_xyz_intr = K.transpose(K.dot(CAM_INTR_COLOR, K.transpose(skel_xyz)))\n",
    "#     skel_uvd = tf.stack([skel_xyz_intr[:, 0]/skel_xyz_intr[:, 2],\n",
    "#                          skel_xyz_intr[:, 1]/skel_xyz_intr[:, 2],\n",
    "#                          skel_xyz_intr[:, 2]], axis = 1)\n",
    "\n",
    "#     return skel_uvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(845,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((845)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def l2_dist(a, b, ax=-1):\n",
    "    return K.sqrt(K.sum(K.square(a - b), axis=ax, keepdims=True))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    index = K.constant(np.ones((21,3)))\n",
    "    index_2 = K.constant(np.zeros((21,3)))\n",
    "#     print(K.shape(index).eval())\n",
    "#     print(l2_dist(index, index_2, -1).eval())\n",
    "    test = K.arange(50)\n",
    "#     print(test.eval())\n",
    "#     zz = tf.where(K.greater(test, 4))\n",
    "#     print(zz.eval())\n",
    "#     print(tf.gather_nd(test, zz).eval())\n",
    "    print(K.cast(K.greater(test,4).eval(), dtype=tf.float32).eval())\n",
    "#     print(test[zz].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     train_pairs = []\n",
    "#     test_pairs = []\n",
    "#     with open(os.path.join(constants.DATASET_DIR, 'data_split_action_recognition.txt')) as f:\n",
    "#         cur_split = 'Training'\n",
    "#         lines = f.readlines()\n",
    "#         for l in lines:\n",
    "#             words = l.split()\n",
    "#             if(words[0] == 'Training' or words[0] == 'Test'):\n",
    "#                 cur_split = words[0]\n",
    "#             else:\n",
    "#                 path = l.split()[0]\n",
    "#                 full_path = os.path.join(constants.IMG_DIR, path, 'color')\n",
    "#                 len_frame_idx = len([x for x in os.listdir(full_path)\n",
    "#                                     if os.path.join(full_path, x)])\n",
    "#                 skeleton_path = os.path.join(constants.SKEL_DIR, path, 'skeleton.txt')\n",
    "#                 skeleton_vals = np.loadtxt(skeleton_path)\n",
    "#                 for i in range(len_frame_idx):\n",
    "#                     img_path = os.path.join(constants.IMG_DIR, path, 'color', 'color_%04d.jpeg' %i)\n",
    "#                     skel_xyz = skeleton_vals[:, 1:].reshape(skeleton_vals.shape[0], 21, 3)[i]\n",
    "#                     data_pair = (img_path, skel_xyz)\n",
    "#                     if cur_split == 'Training':\n",
    "#                         train_pairs.append(data_pair)\n",
    "#                     else:\n",
    "#                         test_pairs.append(data_pair)\n",
    "\n",
    "#     generator = DataGenerator(train_pairs)\n",
    "#     from matplotlib import pyplot as plt\n",
    "#     data = generator[0]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.imshow(data[0][0])\n",
    "#     skel_proj = utils.xyz2uvd(np.reshape(data[1][0], (21,3)), camcoord=True)\n",
    "#     utils.visualize_joints_2d(ax, skel_proj[constants.REORDER], joint_idxs=False)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
