{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../src\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = '/media/aaron/DATA/ubuntu/fpha-dataset/'\n",
    "dataset_dir = '/media/aaron/DATADRIVE1/First_Person_Action_Benchmark'\n",
    "image_dir = os.path.join(dataset_dir, 'Video_files')\n",
    "annot_dir = os.path.join(dataset_dir, 'Hand_pose_annotation_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = [x for x in os.listdir(image_dir) \n",
    "              if os.path.isdir(os.path.join(image_dir, x))]\n",
    "print(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [x for x in os.listdir(os.path.join(image_dir, subject_list[0])) \n",
    "              if os.path.isdir(os.path.join(os.path.join(image_dir, subject_list[0]), x))]\n",
    "print(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(image_dir, subject_list[0], action_list[0]) \n",
    "\n",
    "video_id_list = [x for x in os.listdir(img_path) \n",
    "              if os.path.isdir(os.path.join(img_path, x))]\n",
    "print(video_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_colour = os.path.join(img_path, video_id_list[0], 'color')\n",
    "img_path_depth = os.path.join(img_path, video_id_list[0], 'depth')\n",
    "\n",
    "img_colour_list = [x for x in os.listdir(img_path_colour) \n",
    "              if os.path.join(img_path_colour, x)]\n",
    "img_depth_list = [x for x in os.listdir(img_path_depth) \n",
    "              if os.path.join(img_path_depth, x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    'subject': subject_list[0],\n",
    "    'action_name': action_list[0],\n",
    "    'seq_idx': video_id_list[0],\n",
    "    'frame_idx': 0,\n",
    "    'object': None\n",
    "}\n",
    "\n",
    "\n",
    "img_color_path = os.path.join(image_dir, \n",
    "                   sample['subject'], \n",
    "                   sample['action_name'],\n",
    "                   sample['seq_idx'],\n",
    "                   'color',\n",
    "                   'color_%04d.jpeg' %sample['frame_idx'])\n",
    "\n",
    "img_depth_path = os.path.join(image_dir, \n",
    "                   sample['subject'], \n",
    "                   sample['action_name'],\n",
    "                   sample['seq_idx'],\n",
    "                   'depth',\n",
    "                   'depth_%04d.png' %sample['frame_idx'])\n",
    "\n",
    "img_color = cv2.imread(img_color_path)[:,:,::-1]\n",
    "img_depth = cv2.imread(img_depth_path)[:,:,0]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(18, 16))\n",
    "# ax[0].imshow(img_color[:, :, ::-1])\n",
    "# ax[0].set_title('color')\n",
    "# ax[1].imshow(img_depth[:,:,0])\n",
    "# ax[1].set_title('depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_idx = np.array([\n",
    "    0, 1, 6, 7, 8, 2, 9, 10, 11, 3, 12, 13, 14, 4, 15, 16, 17, 5, 18, 19,\n",
    "    20\n",
    "])\n",
    "skel = utils.get_skeleton(sample, annot_dir)[reorder_idx]\n",
    "print('skel=', skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_path = os.path.join(annot_dir, sample['subject'],\n",
    "                             sample['action_name'], sample['seq_idx'],\n",
    "                             'skeleton.txt')\n",
    "skeleton_vals = np.loadtxt(skeleton_path)\n",
    "skeleton = skeleton_vals[:, 1:].reshape(skeleton_vals.shape[0], 21,\n",
    "                                        -1)\n",
    "print('min depth=', np.min(skeleton[:,:,2]))\n",
    "print('max depth=',np.max(skeleton[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('color.shape=', img_color.shape)\n",
    "print('depth.shape=', img_depth.shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 16))\n",
    "ax[0].imshow(img_color)\n",
    "ax[0].set_title('color')\n",
    "ax[1].imshow(img_depth, cmap='gray')\n",
    "ax[1].set_title('depth')\n",
    "\n",
    "#xyz to uvd\n",
    "\n",
    "cam_extr = np.array(\n",
    "    [[0.999988496304, -0.00468848412856, 0.000982563360594,\n",
    "      25.7], [0.00469115935266, 0.999985218048, -0.00273845880292, 1.22],\n",
    "     [-0.000969709653873, 0.00274303671904, 0.99999576807,\n",
    "      3.902], [0, 0, 0, 1]])\n",
    "cam_intr_color = np.array([[1395.749023, 0, 935.732544],\n",
    "                     [0, 1395.749268, 540.681030], [0, 0, 1]])\n",
    "cam_intr_depth = np.array([[475.065948, 0,  315.944855],\n",
    "                     [0, 475.065857, 245.287079], [0, 0, 1]])\n",
    "\n",
    "skel_hom = np.concatenate([skel, np.ones([skel.shape[0], 1])], 1)\n",
    "# print('skel_hom=', skel_hom)\n",
    "skel_camcoords = cam_extr.dot(\n",
    "    skel_hom.transpose()).transpose()[:, :3].astype(np.float32)\n",
    "# print('skel_camcoords=', skel_camcoords)\n",
    "\n",
    "skel_hom2d_color = np.array(cam_intr_color).dot(skel_camcoords.transpose()).transpose()\n",
    "skel_proj_color_3d = (skel_hom2d_color / skel_hom2d_color[:, 2:])\n",
    "skel_proj_color = skel_proj_color_3d[:, :2]\n",
    "\n",
    "skel_hom2d_depth = np.array(cam_intr_depth).dot(skel.transpose()).transpose()\n",
    "skel_proj_depth_3d = (skel_hom2d_depth / skel_hom2d_depth[:, 2:])\n",
    "skel_proj_depth = skel_proj_depth_3d[:, :2]\n",
    "\n",
    "utils.visualize_joints_2d(ax[0], skel_proj_color, joint_idxs=False)\n",
    "utils.visualize_joints_2d(ax[1], skel_proj_depth, joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_uvd_color = skel_hom2d_color\n",
    "skel_uvd_color[:, :2] =  (skel_hom2d_color[:, :2]/skel_hom2d_color[:, 2:])\n",
    "\n",
    "#uvd to xyz\n",
    "skel_uvd_color[:, :2] = skel_uvd_color[:, :2]*skel_uvd_color[:, 2:]\n",
    "\n",
    "inv_cam_intr_color = np.linalg.inv(cam_intr_color)\n",
    "skel_camcoords_2 = np.array(inv_cam_intr_color).dot(skel_uvd_color.transpose()).transpose()\n",
    "skel_camcoords_2 = np.concatenate([skel_camcoords_2, np.ones([skel_camcoords.shape[0], 1])], 1)\n",
    "inv_cam_extr_color = np.linalg.inv(cam_extr)\n",
    "skel_xyz_color = np.array(inv_cam_extr_color).dot(skel_camcoords_2.transpose()).transpose()\n",
    "\n",
    "# print('reconstructed xyz=', skel_xyz_color[:, :3])\n",
    "# print('original xyz=', skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "#color\n",
    "seq = iaa.Sequential([\n",
    "    iaa.size.Resize({\"height\": 416, \"width\": 416}),\n",
    "    iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "    iaa.WithChannels(0, iaa.Add((0, 30))), #hue\n",
    "    iaa.WithChannels(1, iaa.Add((0, 30))), #saturation\n",
    "    iaa.WithChannels(2, iaa.Add((0, 60))), #exposure\n",
    "    iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\"),\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}),\n",
    "])\n",
    "\n",
    "seq_det = seq.to_deterministic()\n",
    "\n",
    "skel_color_kps = []\n",
    "for kps in skel_proj_color:\n",
    "    skel_color_kps.append(ia.Keypoint(x=kps[0],y=kps[1]))\n",
    "skel_color_kpsoi = ia.KeypointsOnImage(skel_color_kps, shape=img_color.shape)\n",
    "\n",
    "images_aug_color = seq_det.augment_images([img_color])[0]\n",
    "skel_aug_color = seq_det.augment_keypoints([skel_color_kpsoi])[0]\n",
    "\n",
    "skel_proj_color_aug = []\n",
    "for kps in skel_aug_color.keypoints:\n",
    "    skel_proj_color_aug.append([kps.x_int, kps.y_int])\n",
    "skel_proj_color_aug = np.asarray(skel_proj_color_aug)\n",
    "\n",
    "#depth\n",
    "seq = iaa.Sequential([\n",
    "    iaa.size.Resize({\"height\": 416, \"width\": 416}),\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}),\n",
    "])\n",
    "\n",
    "seq_det = seq.to_deterministic()\n",
    "\n",
    "skel_depth_kps = []\n",
    "for kps in skel_proj_depth:\n",
    "    skel_depth_kps.append(ia.Keypoint(x=kps[0],y=kps[1]))\n",
    "skel_depth_kpsoi = ia.KeypointsOnImage(skel_depth_kps, shape=img_depth.shape)\n",
    "    \n",
    "images_aug_depth = seq_det.augment_images([img_depth])[0]\n",
    "skel_aug_depth = seq_det.augment_keypoints([skel_depth_kpsoi])[0]\n",
    "\n",
    "skel_proj_depth_aug = []\n",
    "for kps in skel_aug_depth.keypoints:\n",
    "    skel_proj_depth_aug.append([kps.x_int, kps.y_int])\n",
    "skel_proj_depth_aug = np.asarray(skel_proj_depth_aug)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 16))\n",
    "ax[0].imshow(images_aug_color)\n",
    "ax[0].set_title('color')\n",
    "ax[1].imshow(images_aug_depth)\n",
    "ax[1].set_title('depth')\n",
    "\n",
    "\n",
    "utils.visualize_joints_2d(ax[0], skel_proj_color_aug, joint_idxs=False)\n",
    "utils.visualize_joints_2d(ax[1], skel_proj_depth_aug, joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get split data\n",
    "\n",
    "train_pairs = []\n",
    "test_pairs = []\n",
    "with open(os.path.join(dataset_dir, 'data_split_action_recognition.txt')) as f:\n",
    "    cur_split = 'Training'\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        if(words[0] == 'Training' or words[0] == 'Test'):\n",
    "            cur_split = words[0]\n",
    "        else:\n",
    "            path = l.split()[0]\n",
    "            full_path = os.path.join(image_dir, path, 'color')\n",
    "            len_frame_idx = len([x for x in os.listdir(full_path)\n",
    "                                if os.path.join(full_path, x)])\n",
    "            skeleton_path = os.path.join(annot_dir, path, 'skeleton.txt')\n",
    "            skeleton_vals = np.loadtxt(skeleton_path)\n",
    "            for i in range(len_frame_idx):\n",
    "                img_path = os.path.join(image_dir, path, 'color', 'color_%04d.jpeg' %i)\n",
    "                skel_xyz = skeleton_vals[:, 1:].reshape(skeleton_vals.shape[0], -1)[i]\n",
    "                data_pair = (img_path, skel_xyz)\n",
    "                if cur_split == 'Training':\n",
    "                    train_pairs.append(data_pair)\n",
    "                else:\n",
    "                    test_pairs.append(data_pair)\n",
    "                    \n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
