{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "WORK_DIR = Path(Path.cwd()).parent\n",
    "sys.path.append(str(WORK_DIR))\n",
    "from src.datasets import get_dataset, get_dataloader\n",
    "from src.utils import parse_data_cfg, IMG, FPHA, LMDB, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = parse_data_cfg(WORK_DIR/'data_cfg'/'exp1/multireso_from_pred_data.cfg')\n",
    "exp_dir = cfg[\"exp_dir\"]\n",
    "data_split = 'test'\n",
    "split_set = cfg[data_split + '_set']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = LMDB.get_keys(os.path.join(DATA_DIR, split_set + \"_keys_cache.p\"))\n",
    "xyz_gt = LMDB.read_all_lmdb_dataroot(keys, os.path.join(DATA_DIR, split_set + '_xyz_gt.lmdb'), 'float32', (21, 3))\n",
    "uvd_gt = FPHA.xyz2uvd_color(xyz_gt)\n",
    "pred_file = os.path.join(DATA_DIR, exp_dir, 'predict_{}_uvd_from_pred.txt'.format(data_split))\n",
    "pred_uvd = np.reshape(np.loadtxt(pred_file), (-1, 21, 3))\n",
    "pred_uvd[..., 2] *= 1000\n",
    "\n",
    "file_name = os.path.join(DATA_DIR, exp_dir, 'xy_offset_{}_from_pred.txt'.format(data_split))\n",
    "xy_offset = np.reshape(np.loadtxt(file_name), (-1, 4))\n",
    "\n",
    "pred_uvd_ofs = []\n",
    "for i in tqdm(range(pred_uvd.shape[0])):\n",
    "    pred = IMG.scale_points_WH(pred_uvd[i], (1, 1), (xy_offset[i, 2], xy_offset[i, 3]))\n",
    "    pred[:, 0] += xy_offset[i, 0]\n",
    "    pred[:, 1] += xy_offset[i, 1]\n",
    "    pred = IMG.scale_points_WH(pred, (416, 416), (FPHA.ORI_WIDTH, FPHA.ORI_HEIGHT))    \n",
    "    pred_uvd_ofs.append(pred)\n",
    "pred_uvd_ofs = np.asarray(pred_uvd_ofs)\n",
    "pred_xyz_ofs = FPHA.uvd2xyz_color(pred_uvd_ofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 43752\n",
    "print(keys[idx])\n",
    "img = np.asarray(Image.open(os.path.join(DATA_DIR, 'First_Person_Action_Benchmark', 'Video_files', keys[idx])))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "FPHA.visualize_joints_2d(ax, pred_uvd_ofs[idx][FPHA.REORDER_IDX], joint_idxs=False, c='r')\n",
    "FPHA.visualize_joints_2d(ax, uvd_gt[idx][FPHA.REORDER_IDX], joint_idxs=False, c='b')\n",
    "\n",
    "cur_uvd_gt = uvd_gt[idx]\n",
    "cur_pred_uvd = pred_uvd[idx]\n",
    "img = np.asarray(Image.open(os.path.join(DATA_DIR, 'First_Person_Action_Benchmark', 'Video_files_rsz', keys[idx])))\n",
    "crop, cur_uvd_gt, _, _ = FPHA.crop_hand(img, cur_uvd_gt)\n",
    "cur_uvd_gt  = IMG.scale_points_WH(cur_uvd_gt, (crop.shape[1], crop.shape[0]), (96, 96))\n",
    "cur_pred_uvd = IMG.scale_points_WH(cur_pred_uvd, (1, 1), (96, 96))\n",
    "crop = IMG.resize_img(crop, (96, 96))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(crop)\n",
    "FPHA.visualize_joints_2d(ax, cur_pred_uvd[FPHA.REORDER_IDX], joint_idxs=False, c='r')\n",
    "FPHA.visualize_joints_2d(ax, cur_uvd_gt[FPHA.REORDER_IDX], joint_idxs=False, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(221)\n",
    "ax.imshow(crop)\n",
    "FPHA.visualize_joints_2d(ax, cur_pred_uvd[FPHA.REORDER_IDX], joint_idxs=False, c='r')\n",
    "FPHA.visualize_joints_2d(ax, cur_uvd_gt[FPHA.REORDER_IDX], joint_idxs=False, c='b')\n",
    "\n",
    "for proj_idx, (proj_1, proj_2) in enumerate([[0, 1], [1, 2], [0, 2]]):\n",
    "    ax = fig.add_subplot(2, 2, 2 + proj_idx)\n",
    "    if proj_idx == 0:\n",
    "        # Invert y axes to align with image in camera projection\n",
    "        ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    FPHA.visualize_joints_2d(ax,\n",
    "                        np.stack(\n",
    "                            [cur_pred_uvd[FPHA.REORDER_IDX][:, proj_1], \n",
    "                             cur_pred_uvd[FPHA.REORDER_IDX][:, proj_2]],\n",
    "                            axis=1),\n",
    "                        joint_idxs=False, c='r')\n",
    "    FPHA.visualize_joints_2d(ax,\n",
    "                        np.stack(\n",
    "                            [cur_uvd_gt[FPHA.REORDER_IDX][:, proj_1], \n",
    "                             cur_uvd_gt[FPHA.REORDER_IDX][:, proj_2]],\n",
    "                            axis=1),\n",
    "                        joint_idxs=False, c='b')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s UVD mean_l2_error: ' %data_split, FPHA.mean_L2_error(uvd_gt[:len(pred_uvd_ofs)], pred_uvd_ofs))\n",
    "print('%s XYZ mean_l2_error: ' %data_split, FPHA.mean_L2_error(xyz_gt[:len(pred_uvd_ofs)], pred_xyz_ofs))\n",
    "error = []\n",
    "for i, (pred, uvd) in enumerate(zip(pred_uvd_ofs, uvd_gt)):\n",
    "#     print(i, FPHA.mean_L2_error(uvd, pred))\n",
    "    error.append(FPHA.mean_L2_error(uvd, pred))\n",
    "error = np.asarray(error)\n",
    "min_error_idx = np.argmin(error)\n",
    "max_error_idx = np.argmax(error)\n",
    "print('Best Pose id:', min_error_idx, 'uvd_error:', error[min_error_idx])\n",
    "print('Worst Pose id:', max_error_idx, 'uvd_error:', error[max_error_idx])\n",
    "for idx in np.argsort(error):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pck = FPHA.percentage_frames_within_error_curve(xyz_gt[:len(pred_uvd)], pred_xyz_ofs)\n",
    "pck_str = ''\n",
    "for p in pck:\n",
    "    pck_str += str(p) + ', '\n",
    "print(pck_str)\n",
    "thresholds = np.arange(0, 85, 5)\n",
    "print('AUC:', FPHA.calc_auc(pck, thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
