{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "sys.path.append(str(Path(Path.cwd()).parent))\n",
    "from src.utils import DATA_DIR, IMG, RHD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = 'training'\n",
    "\n",
    "# load annotations of this set\n",
    "anno_all = RHD.load_annot(DATA_DIR, set)\n",
    "\n",
    "sample_id = 28140\n",
    "anno = anno_all[sample_id]\n",
    "\n",
    "print(len(anno_all))\n",
    "for key, val in anno.items():\n",
    "    print(key)\n",
    "\n",
    "# load data\n",
    "image = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'color', '%.5d.png' % sample_id)))\n",
    "mask = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'mask', '%.5d.png' % sample_id)))\n",
    "depth = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'depth', '%.5d.png' % sample_id)))\n",
    "\n",
    "# process rgb coded depth into float: top bits are stored in red, bottom in green channel\n",
    "depth = RHD.depth_two_uint8_to_float(depth[:, :, 0], depth[:, :, 1])  # depth in meters from the camera\n",
    "\n",
    "# get info from annotation dictionary\n",
    "kp_coord_uv = anno['uv_vis'][:, :2]  # u, v coordinates of 42 hand keypoints, pixel\n",
    "kp_visible = (anno['uv_vis'][:, 2] == 1)  # visibility of the keypoints, boolean\n",
    "kp_coord_xyz = anno['xyz']  # x, y, z coordinates of the keypoints, in meters\n",
    "camera_intrinsic_matrix = anno['K']  # matrix containing intrinsic parameters\n",
    "\n",
    "# Project world coordinates into the camera frame\n",
    "kp_coord_uv_proj = np.matmul(kp_coord_xyz, np.transpose(camera_intrinsic_matrix))\n",
    "kp_coord_uv_proj = kp_coord_uv_proj[:, :2] / kp_coord_uv_proj[:, 2:]\n",
    "\n",
    "# Visualize data\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax1 = fig.add_subplot('221')\n",
    "ax2 = fig.add_subplot('222')\n",
    "ax3 = fig.add_subplot('223')\n",
    "ax4 = fig.add_subplot('224', projection='3d')\n",
    "ax1.imshow(image)\n",
    "ax1.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "ax1.plot(kp_coord_uv_proj[kp_visible, 0], kp_coord_uv_proj[kp_visible, 1], 'gx')\n",
    "ax2.imshow(depth)\n",
    "ax3.imshow(mask)\n",
    "ax4.scatter(kp_coord_xyz[kp_visible, 0], kp_coord_xyz[kp_visible, 1], kp_coord_xyz[kp_visible, 2])\n",
    "ax4.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view\n",
    "ax4.set_xlabel('x')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCE the 21 subset using the segmentation masks\n",
    "# We only deal with the more prominent hand for each frame and discard the second set of keypoints\n",
    "\n",
    "# sample_id = 30 # not very visible\n",
    "sample_id = 28139\n",
    "anno = anno_all[sample_id]\n",
    "\n",
    "keypoint_xyz = anno['xyz']\n",
    "keypoint_vis = anno['uv_vis'][:, 2]\n",
    "keypoint_uv = anno['uv_vis'][:, :2]\n",
    "camera_intrinsic_matrix = anno['K']\n",
    "image = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'color', '%.5d.png' % sample_id)))\n",
    "mask = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'mask', '%.5d.png' % sample_id)))\n",
    "\n",
    "cond_l = np.logical_and(np.greater(mask, 1), np.less(mask, 18))\n",
    "cond_r = np.greater(mask, 17)\n",
    "hand_map_l = np.where(cond_l, 1, 0)\n",
    "hand_map_r = np.where(cond_r, 1, 0)\n",
    "num_px_left_hand = np.sum(hand_map_l)\n",
    "num_px_right_hand = np.sum(hand_map_r)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(cond_l)\n",
    "ax[1].imshow(cond_r)\n",
    "\n",
    "kp_coord_xyz_left = keypoint_xyz[:21, :]\n",
    "kp_coord_xyz_right = keypoint_xyz[-21:, :]\n",
    "\n",
    "cond_left = np.logical_and(np.ones(kp_coord_xyz_left.shape), np.greater(num_px_left_hand, num_px_right_hand))\n",
    "kp_coord_xyz21 = np.where(cond_left, kp_coord_xyz_left, kp_coord_xyz_right)\n",
    "\n",
    "kp_coord_uv_proj = np.matmul(kp_coord_xyz21, np.transpose(camera_intrinsic_matrix))\n",
    "kp_coord_uv_proj[:, :2] = kp_coord_uv_proj[:, :2]/kp_coord_uv_proj[:, 2:]\n",
    "\n",
    "kp_coord_xy_proj = kp_coord_uv_proj.copy()\n",
    "kp_coord_xy_proj[:, :2] = kp_coord_uv_proj[:, :2]*kp_coord_uv_proj[:, 2:]\n",
    "kp_coord_xy_proj = np.matmul(kp_coord_xy_proj, np.transpose(np.linalg.inv(camera_intrinsic_matrix)))\n",
    "\n",
    "print(np.allclose(kp_coord_xy_proj, kp_coord_xyz21))\n",
    "\n",
    "keypoint_vis_left = keypoint_vis[:21]\n",
    "keypoint_vis_right = keypoint_vis[-21:]\n",
    "keypoint_vis21 = np.where(cond_left[:, 0], keypoint_vis_left, keypoint_vis_right).astype(bool)\n",
    "\n",
    "keypoint_uv_left = keypoint_uv[:21, :]\n",
    "keypoint_uv_right = keypoint_uv[-21:, :]\n",
    "keypoint_uv21 = np.where(cond_left[:, :2], keypoint_uv_left, keypoint_uv_right)\n",
    "\n",
    "bbox = RHD.get_bbox(kp_coord_uv_proj)\n",
    "\n",
    "crop, uvd_gt_crop = RHD.crop_hand(image, kp_coord_uv_proj)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "# RHD.visualize_joints_2d(ax, kp_coord_uv_proj[RHD.REORDER_IDX])\n",
    "RHD.draw_bbox(ax, bbox, (image.shape[1], image.shape[0]))\n",
    "ax.plot(kp_coord_uv_proj[keypoint_vis21, 0], kp_coord_uv_proj[keypoint_vis21, 1], 'ro')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(crop)\n",
    "# RHD.visualize_joints_2d(ax, uvd_gt_crop[RHD.REORDER_IDX])\n",
    "ax.plot(uvd_gt_crop[keypoint_vis21, 0], uvd_gt_crop[keypoint_vis21, 1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_rsz = IMG.resize_img(crop, (256, 256))\n",
    "uvd_gt_crop_rsz = IMG.scale_points_WH(uvd_gt_crop, (crop.shape[1], crop.shape[0]), (256, 256))\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "scoremap = RHD.create_multiple_gaussian_map(uvd_gt_crop_rsz, (256, 256), 25, keypoint_vis21)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        k = np.ravel_multi_index((i, j), (5, 5))\n",
    "        if k >= scoremap.shape[2]:\n",
    "            break\n",
    "        show_scoremap = cv2.cvtColor(scoremap[:, :, k], cv2.COLOR_GRAY2RGB)\n",
    "        show_scoremap = cv2.normalize(show_scoremap, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8UC3)\n",
    "        show_scoremap[:, :, 0] = 0\n",
    "        show_scoremap[:, :, 2] = 0\n",
    "        show = 0.5*show_scoremap + 0.5*crop_rsz\n",
    "    \n",
    "        ax[i, j].imshow(show.astype('uint32'))\n",
    "        ax[i, j].plot(uvd_gt_crop_rsz[keypoint_vis21, 0], uvd_gt_crop_rsz[keypoint_vis21, 1], 'r.')\n",
    "#         RHD.visualize_joints_2d(ax[i, j], uvd_gt_crop_rsz[RHD.REORDER_IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert = RHD.revert_hand_annot(image, kp_coord_uv_proj, uvd_gt_crop_rsz, (256, 256))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "RHD.visualize_joints_2d(ax, revert[RHD.REORDER_IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = RHD.detect_keypoints_from_scoremap(scoremap)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(crop_rsz)\n",
    "ax.plot(pts[:, 0], pts[:, 1], 'r.')\n",
    "# RHD.visualize_joints_2d(ax, pts[RHD.REORDER_IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'mask', '%.5d.png' % sample_id)))\n",
    "\n",
    "image = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'color', '%.5d.png' % sample_id)))\n",
    "tmp_hand_mask = np.greater(mask, 1)\n",
    "bg_mask = np.logical_not(tmp_hand_mask)\n",
    "hand_mask = np.stack([bg_mask, tmp_hand_mask], 2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cur_mask = bg_mask\n",
    "show_mask = np.stack([np.zeros(cur_mask.shape), np.zeros(cur_mask.shape), cur_mask], 2).astype('uint8')\n",
    "show_img = IMG.scale_img_255(show_mask)\n",
    "show_img = show_img*0.5 + image*0.5\n",
    "show_img = IMG.scale_img_255(show_img)\n",
    "ax.imshow(show_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 28140\n",
    "anno                = anno_all[sample_id]\n",
    "image = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'color', '%.5d.png' % sample_id)))\n",
    "mask = np.asarray(Image.open(os.path.join(DATA_DIR, 'RHD_published_v2', set, 'mask', '%.5d.png' % sample_id)))\n",
    "\n",
    "mask                = np.asarray(mask)\n",
    "K = anno['K']\n",
    "keypoint_xyz        = anno['xyz']\n",
    "keypoint_vis        = anno['uv_vis'][:, 2]\n",
    "keypoint_uv         = anno['uv_vis'][:, :2]\n",
    "# Find dominant hand\n",
    "cond_l              = np.logical_and(np.greater(mask, 1),\n",
    "                                     np.less(mask, 18))\n",
    "cond_r              = np.greater(mask, 17)\n",
    "hand_map_l          = np.where(cond_l, 1, 0)\n",
    "hand_map_r          = np.where(cond_r, 1, 0)\n",
    "num_px_left         = np.sum(hand_map_l)\n",
    "num_px_right        = np.sum(hand_map_r)\n",
    "kp_coord_xyz_left   = keypoint_xyz[:21, :]\n",
    "kp_coord_xyz_right  = keypoint_xyz[-21:, :]\n",
    "cond_left           = np.logical_and(np.ones(kp_coord_xyz_left.shape),\n",
    "                                     np.greater(num_px_left,\n",
    "                                                num_px_right))\n",
    "kp_coord_xyz21      = np.where(cond_left,\n",
    "                               kp_coord_xyz_left, kp_coord_xyz_right)\n",
    "hand_side           = np.where(np.greater(num_px_left, num_px_right), \n",
    "                               0, # left hand \n",
    "                               1) # right hand\n",
    "# Visibility\n",
    "keypoint_vis_left   = keypoint_vis[:21]\n",
    "keypoint_vis_right  = keypoint_vis[-21:]\n",
    "keypoint_vis21      = np.where(cond_left[:, 0],\n",
    "                          keypoint_vis_left,\n",
    "                          keypoint_vis_right).astype('bool')\n",
    "\n",
    "# UV\n",
    "keypoint_uv_left    = keypoint_uv[:21, :]\n",
    "keypoint_uv_right   = keypoint_uv[-21:, :]\n",
    "uvd_gt              = np.where(cond_left[:, :2],\n",
    "                               keypoint_uv_left,\n",
    "                               keypoint_uv_right)\n",
    "uvd_gt = RHD.xyz2uvd(kp_coord_xyz21, K)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(image)\n",
    "# ax.plot(uvd_gt[keypoint_vis21, 0], uvd_gt[keypoint_vis21, 1], 'b.')\n",
    "\n",
    "# Canonical\n",
    "xyz_norm, kpt_scale             = RHD.norm_keypoint(kp_coord_xyz21)\n",
    "xyz_gt_canon, inv_rot_mat       = RHD.canonical_transform(xyz_norm)\n",
    "rot_mat                         = np.linalg.inv(inv_rot_mat)\n",
    "xyz_gt_canon                    = np.squeeze(xyz_gt_canon)\n",
    "if hand_side == 1:\n",
    "    print('switch to')\n",
    "    xyz_gt_canon[:, 2] = -xyz_gt_canon[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "RHD.visualize_joints_2d(ax, xyz_gt_canon[RHD.REORDER_IDX])\n",
    "    \n",
    "\n",
    "if hand_side == 1:\n",
    "    print('switch back')\n",
    "    xyz_gt_canon[:, 2] = -xyz_gt_canon[:, 2]\n",
    "\n",
    "reform_xyz = np.matmul(xyz_gt_canon, rot_mat)*kpt_scale\n",
    "reform_xyz += kp_coord_xyz21[0, :]\n",
    "reform_uvd = RHD.xyz2uvd(reform_xyz, K)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image)\n",
    "ax.plot(uvd_gt[keypoint_vis21, 0], uvd_gt[keypoint_vis21, 1], 'bo')\n",
    "ax.plot(reform_uvd[keypoint_vis21, 0], reform_uvd[keypoint_vis21, 1], 'ro')\n",
    "\n",
    "print(np.allclose(reform_uvd[:, :2], uvd_gt[:, :2]))\n",
    "print(np.allclose(reform_xyz, kp_coord_xyz21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
