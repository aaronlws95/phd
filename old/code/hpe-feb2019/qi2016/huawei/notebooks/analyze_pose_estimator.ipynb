{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "from utils import math,loss,xyz_uvd,hand_utils,get_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "colors_map = cmap(numpy.arange(cmap.N))\n",
    "rng = numpy.random.RandomState(0)\n",
    "num = rng.randint(0,256,(21,))\n",
    "jnt_colors = colors_map[num]\n",
    "# print jnt_colors.shape\n",
    "markersize = 7\n",
    "linewidth=2\n",
    "azim =  -177\n",
    "elev = -177\n",
    "\n",
    "hand_img_size=96\n",
    "hand_size=300.0\n",
    "centerU=315.944855\n",
    "padWidth=100\n",
    "\n",
    "data_dir = '../data'\n",
    "save_dir = os.path.join(data_dir, 'mega/hier/model')\n",
    "img_dir = os.path.join(data_dir, 'mega/test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(save_dir,version):\n",
    "    print('load model',version)\n",
    "    # load json and create model\n",
    "    json_file = open(\"%s/%s.json\"%(save_dir,version), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"%s/weight_%s\"%(save_dir,version))\n",
    "    loaded_model.compile(optimizer=Adam(lr=1e-5), loss=loss.cost_sigmoid)\n",
    "    return loaded_model\n",
    "\n",
    "versions=['pixel_fullimg_ker32_lr0.001000','vass_palm_s0_rot_scale_ker32_lr0.000100']\n",
    "for i in range(5):\n",
    "    versions.append('pip_s0_finger%d_smalljiter_ker48_lr0.000100'%i)\n",
    "    versions.append('dtip_s0_finger%d_smalljiter_ker48_lr0.000100'%i)\n",
    "models=[]\n",
    "for version in versions:\n",
    "    models.append(load_model(save_dir=save_dir,version=version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='test'\n",
    "f = h5py.File(os.path.join(data_dir, 'mega/source/%s_crop_norm_vassi_only.h5'%(dataset)), 'r')\n",
    "new_file_names = f['new_file_names'][...]\n",
    "gt_xyz= f['xyz_gt'][...]\n",
    "f.close()\n",
    "\n",
    "cur_frame = new_file_names[0]\n",
    "depth = Image.open(\"%s/%s.png\"%(img_dir,cur_frame))\n",
    "depth = numpy.asarray(depth, dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=1.8\n",
    "setname='mega'\n",
    "bbsize=300\n",
    "palm_idx=[0,1,5,9,13,17]\n",
    "#load models\n",
    "pose_norm_uvd = numpy.empty((1,21,3))\n",
    "#prediction for palm_stage_0\n",
    "s0 = time.clock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier_Estimator_Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r0,r1,r2,meanUVD = hier_estimator_detector(depth,models[0],setname=setname)\n",
    "#detect hand and get scaled versions as input to next step\n",
    "\n",
    "#U-net mask detection\n",
    "def get_mask(depthimg,model):\n",
    "    depth=numpy.zeros((1,480,640,1))\n",
    "    depth[0,:,:,0] = depthimg/2000.0\n",
    "    mask = model.predict(x=depth,batch_size=1)\n",
    "    mask = math.sigmoid(mask[0,:,:,0])\n",
    "    return mask\n",
    "\n",
    "detector_model = models[0]\n",
    "\n",
    "#get mask\n",
    "mask = get_mask(depthimg=depth,model=detector_model)\n",
    "plt.imshow(mask)\n",
    "plt.title('mask')\n",
    "plt.show()\n",
    "\n",
    "#threshold mask\n",
    "loc = numpy.where(mask>0.5)\n",
    "#check if hand is present\n",
    "if  loc[0].shape[0]<30:\n",
    "    print('no hand in the area or hand too small')\n",
    "#extract mask\n",
    "depth_value = depth[loc]\n",
    "U = numpy.mean(loc[1])\n",
    "V = numpy.mean(loc[0])\n",
    "D = numpy.mean(depth_value)\n",
    "#check if hand area is valid\n",
    "if D<10:\n",
    "    print('not valid hand area')\n",
    "    \n",
    "meanUVD = numpy.array([U,V,D]).reshape(1,1,3)\n",
    "print('meanUVD=', meanUVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = numpy.array([(hand_size,hand_size,numpy.mean(depth_value))])\n",
    "bbox_uvd = xyz_uvd.xyz2uvd(setname=setname,xyz=bb)\n",
    "margin = int(numpy.ceil(bbox_uvd[0,0] - centerU))\n",
    "depth_w_hand_only = depth.copy()\n",
    "loc_back = numpy.where(mask<0.5)\n",
    "depth_w_hand_only[loc_back]=0\n",
    "loc_back = numpy.where(numpy.logical_and(depth_w_hand_only>D+hand_size/2,depth_w_hand_only<D-hand_size/2))\n",
    "depth_w_hand_only[loc_back]=0\n",
    "\n",
    "print('bb=', bb)\n",
    "print('bbox_uvd=', bbox_uvd)\n",
    "print('margin=', margin)\n",
    "\n",
    "tmpDepth = numpy.zeros((depth.shape[0]+padWidth*2,depth.shape[1]+padWidth*2))\n",
    "tmpDepth[padWidth:padWidth+depth.shape[0],padWidth:padWidth+depth.shape[1]]=depth_w_hand_only\n",
    "if U-margin/2+padWidth<0 or U+margin/2+padWidth>tmpDepth.shape[1]-1 or V - margin/2+padWidth <0 or V+margin/2+padWidth>tmpDepth.shape[0]-1:\n",
    "    print('most hand part outside the image')\n",
    "\n",
    "crop = tmpDepth[int(V-margin/2+padWidth):int(V+margin/2+padWidth),int(U-margin/2+padWidth):int(U+margin/2+padWidth)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(18, 16))\n",
    "ax[0].imshow(depth)\n",
    "ax[0].set_title('depth')\n",
    "ax[1].imshow(tmpDepth)\n",
    "ax[1].set_title('depth_w_hand_only')\n",
    "ax[2].imshow(tmpDepth)\n",
    "ax[2].set_title('tmpDepth')\n",
    "ax[3].imshow(crop)\n",
    "ax[3].set_title('crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_hand_img=numpy.ones(crop.shape,dtype='float32')\n",
    "loc_hand=numpy.where(crop>0)\n",
    "norm_hand_img[loc_hand]=(crop[loc_hand]-D)/hand_size\n",
    "r0 = resize(norm_hand_img, (hand_img_size,hand_img_size), order=3,preserve_range=True)\n",
    "r1 = resize(norm_hand_img, (hand_img_size/2,hand_img_size/2), order=3,preserve_range=True)\n",
    "r2 = resize(norm_hand_img, (hand_img_size/4,hand_img_size/4), order=3,preserve_range=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(18, 16))\n",
    "ax[0].imshow(norm_hand_img)\n",
    "ax[0].set_title('norm_hand_img')\n",
    "ax[1].imshow(r0)\n",
    "ax[1].set_title('r0')\n",
    "ax[2].imshow(r1)\n",
    "ax[2].set_title('r1')\n",
    "ax[3].imshow(r2)\n",
    "ax[3].set_title('r2')\n",
    "\n",
    "r0.shape=(1,hand_img_size,hand_img_size,1)\n",
    "r1.shape=(1,int(hand_img_size/2),int(hand_img_size/2),1)\n",
    "r2.shape=(1,int(hand_img_size/4),int(hand_img_size/4),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict palm joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=time.clock()\n",
    "\n",
    "#estimate palm joints\n",
    "palm_norm_uvd = models[1].predict(x={'input0':r0,'input1':r1,'input2':r2},batch_size=1).reshape(1,6,3)\n",
    "pose_norm_uvd[:,palm_idx,:]=palm_norm_uvd\n",
    "print('palm_norm_uvd=', palm_norm_uvd) #each row represents a joint\n",
    "print(palm_norm_uvd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for PIP on finger0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get crop for finger part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_finger = 0\n",
    "\n",
    "#crop0,crop1 = get_crop_for_finger_part_s0(r0=r0,pred_palm_uvd=palm_norm_uvd, jnt_uvd_in_prev_layer=palm_norm_uvd[:,[cur_finger+1]], if_aug=False,scale=scale)\n",
    "# if_aug = False\n",
    "pred_palm_uvd = palm_norm_uvd\n",
    "jnt_uvd_in_prev_layer = palm_norm_uvd[:,[cur_finger+1]]\n",
    "\n",
    "num_frame = r0.shape[0]\n",
    "new_r0 = r0.copy()\n",
    "rot_angle = math.get_angle_between_two_lines(line0=(pred_palm_uvd[:,3,:]-pred_palm_uvd[:,0,:])[:,0:2])\n",
    "print('rot_angle=', rot_angle)\n",
    "crop0 = numpy.empty((num_frame,48,48,1),dtype='float32')\n",
    "crop1 = numpy.empty((num_frame,24,24,1),dtype='float32')\n",
    "\n",
    "# if if_aug:\n",
    "#     # aug_frame=numpy.ones((num_frame,),dtype='uint8')\n",
    "#     aug_frame = numpy.random.uniform(0,1,num_frame)\n",
    "#     aug_frame = numpy.where(aug_frame>0.5,1,0)\n",
    "# else:\n",
    "aug_frame=numpy.zeros((num_frame,),dtype='uint8')\n",
    "\n",
    "#for each r0 in batch\n",
    "for i in range(r0.shape[0]):\n",
    "    cur_pred_uvd=jnt_uvd_in_prev_layer[i]\n",
    "\n",
    "#     if aug_frame[i]:\n",
    "#         cur_pred_uvd+= numpy.random.normal(loc=0,scale=0.05,size=3)\n",
    "#         rot=numpy.random.normal(loc=0,scale=15,size=1)\n",
    "#     else:\n",
    "    rot=0\n",
    "\n",
    "    \"2D translation\"\n",
    "    tx=-cur_pred_uvd[0,0]*96#cols\n",
    "    ty=-cur_pred_uvd[0,1]*96#rows\n",
    "\n",
    "    M = numpy.float32([[1,0,tx],[0,1,ty]])\n",
    "    dst = cv2.warpAffine(new_r0[i,:,:,0],M,(96,96),borderValue=1)\n",
    "    print('M_prev=', M)\n",
    "    dst_prev = dst\n",
    "    \n",
    "    M = cv2.getRotationMatrix2D((48,48),rot+rot_angle[i],scale=scale)\n",
    "    dst= cv2.warpAffine(dst,M,(96,96),borderValue=1)\n",
    "    print('M=', M)\n",
    "    crop0[i,:,:,0]=dst[24:72,24:72]\n",
    "    crop1[i,:,:,0] = resize(crop0[i,:,:,0], (24,24), order=3,preserve_range=True)    \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 16))\n",
    "    ax[0].imshow(dst_prev)\n",
    "    ax[0].set_title('dst_prev') \n",
    "    ax[1].imshow(dst)\n",
    "    ax[1].set_title('dst')  \n",
    "    ax[2].imshow(crop0[i,:,:,0])\n",
    "    ax[2].set_title('crop0')\n",
    "    ax[3].imshow(crop1[i,:,:,0])\n",
    "    ax[3].set_title('crop1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict offset\n",
    "offset = models[cur_finger*2+2].predict(x={'input0':crop0,'input1':crop1},batch_size=1).reshape(1,1,3)\n",
    "print('offset=', offset)\n",
    "\n",
    "# cur_jnt_norm_uvd = get_err.get_normuvd_from_offset(offset=offset,\n",
    "#                                                    pred_palm=palm_norm_uvd,\n",
    "#                                                    jnt_uvd_in_prev_layer=palm_norm_uvd[:,[cur_finger+1]],\n",
    "#                                                    scale=scale)\n",
    "pred_palm=palm_norm_uvd\n",
    "jnt_uvd_in_prev_layer=palm_norm_uvd[:,[cur_finger+1]]\n",
    "\n",
    "rot_angle = math.get_angle_between_two_lines(line0=(pred_palm[:,3,:]-pred_palm[:,0,:])[:,0:2])\n",
    "print('rot_angle=', rot_angle)\n",
    "\n",
    "for i in range(offset.shape[0]):\n",
    "    M = cv2.getRotationMatrix2D((48,48),-rot_angle[i],1/scale)\n",
    "    print('M=', M)\n",
    "    for j in range(offset.shape[1]):\n",
    "        offset[i,j,0:2] = (numpy.dot(M,numpy.array([offset[i,j,0]*96+48,offset[i,j,1]*96+48,1]))-48)/96\n",
    "        print('offset_new=', offset)        \n",
    "pred_uvd = jnt_uvd_in_prev_layer+offset\n",
    "print('jnt_uvd_in_prev_layer=', jnt_uvd_in_prev_layer)\n",
    "print('pred_uvd', pred_uvd)\n",
    "\n",
    "cur_jnt_norm_uvd = pred_uvd\n",
    "cur_jnt_idx=[cur_finger*4+1+1]\n",
    "pose_norm_uvd[:,cur_jnt_idx]=cur_jnt_norm_uvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for DTIP on finger0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get crop for finger part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_palm_uvd = palm_norm_uvd\n",
    "jnt_uvd_in_prev_layer = cur_jnt_norm_uvd\n",
    "\n",
    "num_frame = r0.shape[0]\n",
    "new_r0 = r0.copy()\n",
    "rot_angle = math.get_angle_between_two_lines(line0=(pred_palm_uvd[:,3,:]-pred_palm_uvd[:,0,:])[:,0:2])\n",
    "print('rot_angle=', rot_angle)\n",
    "crop0 = numpy.empty((num_frame,48,48,1),dtype='float32')\n",
    "crop1 = numpy.empty((num_frame,24,24,1),dtype='float32')\n",
    "\n",
    "# if if_aug:\n",
    "#     # aug_frame=numpy.ones((num_frame,),dtype='uint8')\n",
    "#     aug_frame = numpy.random.uniform(0,1,num_frame)\n",
    "#     aug_frame = numpy.where(aug_frame>0.5,1,0)\n",
    "# else:\n",
    "aug_frame=numpy.zeros((num_frame,),dtype='uint8')\n",
    "\n",
    "#for each r0 in batch\n",
    "for i in range(r0.shape[0]):\n",
    "    cur_pred_uvd=jnt_uvd_in_prev_layer[i]\n",
    "\n",
    "#     if aug_frame[i]:\n",
    "#         cur_pred_uvd+= numpy.random.normal(loc=0,scale=0.05,size=3)\n",
    "#         rot=numpy.random.normal(loc=0,scale=15,size=1)\n",
    "#     else:\n",
    "    rot=0\n",
    "\n",
    "    \"2D translation\"\n",
    "    tx=-cur_pred_uvd[0,0]*96#cols\n",
    "    ty=-cur_pred_uvd[0,1]*96#rows\n",
    "\n",
    "    M = numpy.float32([[1,0,tx],[0,1,ty]])\n",
    "    dst = cv2.warpAffine(new_r0[i,:,:,0],M,(96,96),borderValue=1)\n",
    "    print('M_prev=', M)\n",
    "    dst_prev = dst\n",
    "    \n",
    "    M = cv2.getRotationMatrix2D((48,48),rot+rot_angle[i],scale=scale)\n",
    "    dst= cv2.warpAffine(dst,M,(96,96),borderValue=1)\n",
    "    print('M=', M)\n",
    "    crop0[i,:,:,0]=dst[24:72,24:72]\n",
    "    crop1[i,:,:,0] = resize(crop0[i,:,:,0], (24,24), order=3,preserve_range=True)    \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 16))\n",
    "    ax[0].imshow(dst_prev)\n",
    "    ax[0].set_title('dst_prev') \n",
    "    ax[1].imshow(dst)\n",
    "    ax[1].set_title('dst')  \n",
    "    ax[2].imshow(crop0[i,:,:,0])\n",
    "    ax[2].set_title('crop0')\n",
    "    ax[3].imshow(crop1[i,:,:,0])\n",
    "    ax[3].set_title('crop1')\n",
    "    \n",
    "cur_jnt_idx=[cur_finger*4+2+1,cur_finger*4+3+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict offset\n",
    "offset = models[cur_finger*2+3].predict(x={'input0':crop0,'input1':crop1},batch_size=1).reshape(1,2,3)\n",
    "print('offset=', offset)\n",
    "\n",
    "pred_palm=palm_norm_uvd\n",
    "jnt_uvd_in_prev_layer=cur_jnt_norm_uvd\n",
    "\n",
    "rot_angle = math.get_angle_between_two_lines(line0=(pred_palm[:,3,:]-pred_palm[:,0,:])[:,0:2])\n",
    "print('rot_angle=', rot_angle)\n",
    "\n",
    "for i in range(offset.shape[0]):\n",
    "    M = cv2.getRotationMatrix2D((48,48),-rot_angle[i],1/scale)\n",
    "    print('M=', M)\n",
    "    for j in range(offset.shape[1]):\n",
    "        offset[i,j,0:2] = (numpy.dot(M,numpy.array([offset[i,j,0]*96+48,offset[i,j,1]*96+48,1]))-48)/96\n",
    "        print('offset_new=', offset)        \n",
    "pred_uvd = jnt_uvd_in_prev_layer+offset\n",
    "print('jnt_uvd_in_prev_layer=', jnt_uvd_in_prev_layer)\n",
    "print('pred_uvd', pred_uvd)\n",
    "\n",
    "cur_jnt_norm_uvd = pred_uvd\n",
    "\n",
    "pose_norm_uvd[:,cur_jnt_idx]=cur_jnt_norm_uvd\n",
    "# print('pose_norm_uvd=', pose_norm_uvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for other fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_for_finger_part_s0(r0,pred_palm_uvd,jnt_uvd_in_prev_layer,if_aug=True,scale=1.8):\n",
    "    num_frame=r0.shape[0]\n",
    "    new_r0=r0.copy()\n",
    "    rot_angle = math.get_angle_between_two_lines(line0=(pred_palm_uvd[:,3,:]-pred_palm_uvd[:,0,:])[:,0:2])\n",
    "\n",
    "    crop0=numpy.empty((num_frame,48,48,1),dtype='float32')\n",
    "    crop1 = numpy.empty((num_frame,24,24,1),dtype='float32')\n",
    "\n",
    "\n",
    "    if if_aug:\n",
    "        # aug_frame=numpy.ones((num_frame,),dtype='uint8')\n",
    "        aug_frame = numpy.random.uniform(0,1,num_frame)\n",
    "        aug_frame = numpy.where(aug_frame>0.5,1,0)\n",
    "    else:\n",
    "        aug_frame=numpy.zeros((num_frame,),dtype='uint8')\n",
    "    for i in range(r0.shape[0]):\n",
    "\n",
    "        cur_pred_uvd=jnt_uvd_in_prev_layer[i]\n",
    "        # print(cur_pred_uvd.shape,cur_pred_uvd.shape)\n",
    "\n",
    "        if aug_frame[i]:\n",
    "            cur_pred_uvd+= numpy.random.normal(loc=0,scale=0.05,size=3)\n",
    "            rot=numpy.random.normal(loc=0,scale=15,size=1)\n",
    "        else:\n",
    "            rot=0\n",
    "        # print(cur_pred_uvd.shape)\n",
    "        \"2D translation\"\n",
    "        tx=-cur_pred_uvd[0,0]*96#cols\n",
    "        ty=-cur_pred_uvd[0,1]*96#rows\n",
    "\n",
    "        M = numpy.float32([[1,0,tx],[0,1,ty]])\n",
    "        dst = cv2.warpAffine(new_r0[i,:,:,0],M,(96,96),borderValue=1)\n",
    "\n",
    "        M = cv2.getRotationMatrix2D((48,48),rot+rot_angle[i],scale=scale)\n",
    "        dst= cv2.warpAffine(dst,M,(96,96),borderValue=1)\n",
    "\n",
    "        crop0[i,:,:,0]=dst[24:72,24:72]\n",
    "        crop1[i,:,:,0] = resize(crop0[i,:,:,0], (24,24), order=3,preserve_range=True)\n",
    "\n",
    "    return crop0,crop1\n",
    "\n",
    "\n",
    "for cur_finger in [1,2,3,4]:\n",
    "    \"make prediction for pip on cur_finger\"\n",
    "    crop0,crop1 = get_crop_for_finger_part_s0(r0=r0,pred_palm_uvd=palm_norm_uvd, jnt_uvd_in_prev_layer=palm_norm_uvd[:,[cur_finger+1]], if_aug=False,scale=scale)\n",
    "    offset= models[cur_finger*2+2].predict(x={'input0':crop0,'input1':crop1},batch_size=1).reshape(1,1,3)\n",
    "    cur_jnt_norm_uvd = get_err.get_normuvd_from_offset(offset=offset,pred_palm=palm_norm_uvd,\n",
    "                                                      jnt_uvd_in_prev_layer=palm_norm_uvd[:,[cur_finger+1]],scale=scale)\n",
    "    # print(cur_jnt_norm_uvd)\n",
    "    cur_jnt_idx=[cur_finger*4+1+1]\n",
    "    pose_norm_uvd[:,cur_jnt_idx]=cur_jnt_norm_uvd\n",
    "    \"make prediction for dtip on cur_finger\"\n",
    "    crop0,crop1 = get_crop_for_finger_part_s0(r0=r0,pred_palm_uvd=palm_norm_uvd,\n",
    "                                              jnt_uvd_in_prev_layer=cur_jnt_norm_uvd,\n",
    "                                              if_aug=False,scale=scale)\n",
    "    cur_jnt_idx=[cur_finger*4+2+1,cur_finger*4+3+1]\n",
    "    offset = models[cur_finger*2+3].predict(x={'input0':crop0,'input1':crop1},batch_size=1).reshape(1,2,3)\n",
    "    cur_jnt_norm_uvd = get_err.get_normuvd_from_offset(offset=offset,pred_palm=palm_norm_uvd,\n",
    "                                                      jnt_uvd_in_prev_layer=cur_jnt_norm_uvd,scale=scale)\n",
    "    pose_norm_uvd[:,cur_jnt_idx]=cur_jnt_norm_uvd\n",
    "#     print('pose_norm_uvd=', pose_norm_uvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get XYZ from NORMUVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xyz_from_normuvd(normuvd,uvd_hand_centre,jnt_idx,setname,bbsize):\n",
    "    if setname =='icvl':\n",
    "        centerU=320/2\n",
    "    if setname =='nyu':\n",
    "        centerU=640/2\n",
    "    if setname =='msrc':\n",
    "        centerU=512/2\n",
    "    if setname=='mega':\n",
    "        centerU=315.944855\n",
    "    numImg=normuvd.shape[0]\n",
    "\n",
    "    bbsize_array = numpy.ones((numImg,3))*bbsize\n",
    "    bbsize_array[:,2]=uvd_hand_centre[:,0,2]\n",
    "    bbox_uvd = xyz_uvd.xyz2uvd(setname=setname,xyz=bbsize_array)\n",
    "    normUVSize = numpy.array(numpy.ceil(bbox_uvd[:,0]) - centerU,dtype='int32')\n",
    "    normuvd=normuvd[:numImg].reshape(numImg,len(jnt_idx),3)\n",
    "    uvd = numpy.empty_like(normuvd)\n",
    "    uvd[:,:,2]=normuvd[:,:,2]*bbsize\n",
    "    uvd[:,:,0:2]=normuvd[:,:,0:2]*normUVSize.reshape(numImg,1,1)\n",
    "    uvd += uvd_hand_centre\n",
    "\n",
    "    xyz_pred = xyz_uvd.uvd2xyz(setname=setname,uvd=uvd)\n",
    "    return xyz_pred,uvd\n",
    "\n",
    "xyz_pred ,uvd_pred = get_xyz_from_normuvd(normuvd=pose_norm_uvd,uvd_hand_centre=meanUVD,jnt_idx=range(21),setname=setname,bbsize=bbsize)\n",
    "\n",
    "print('xyz_pred=', xyz_pred, xyz_pred.shape)\n",
    "print('uvd_pred=', uvd_pred, uvd_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=time.clock()\n",
    "print('fps full',int(1/(s2-s0)),'pose',int(1/(s2-s1)),'detect',int(1/(s1-s0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgcopy=depth.copy()\n",
    "min = imgcopy.min()\n",
    "max = imgcopy.max()\n",
    "#scale to 0 - 255\n",
    "imgcopy = (imgcopy - min) / (max - min) * 255. \n",
    "imgcopy = imgcopy.astype('uint8')\n",
    "imgcopy = cv2.cvtColor(imgcopy, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#visualize annotation\n",
    "for j in range(uvd_pred.shape[1]):\n",
    "    cv2.circle(imgcopy,(int(uvd_pred[0,j,0]),int(uvd_pred[0,j,1])), int(3000.0/numpy.mean(uvd_pred[0,j,2])), (0, 255, 0), -1)\n",
    "    \n",
    "print(cur_frame)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "ax.imshow(imgcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
