{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import sys\n",
    "import lmdb\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from utils.directory import DATA_DIR, DATASET_DIR\n",
    "from utils.directory import DATA_DIR, DATASET_DIR\n",
    "import utils.prepare_data as pd\n",
    "import utils.error as error\n",
    "import utils.visualize as visual\n",
    "import utils.convert_xyz_uvd as xyzuvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prefix = 'test_fpha'\n",
    "REORDER = visual.REORDER\n",
    "keys_cache_file = os.path.join(DATA_DIR, save_prefix + '_keys_cache.p')\n",
    "keys = pickle.load(open(keys_cache_file, \"rb\"))\n",
    "idx = 0\n",
    "key = keys[idx]\n",
    "dataroot_uvd_gt_scaled = os.path.join(DATA_DIR, save_prefix + '_uvd_gt_scaled.lmdb')\n",
    "uvd_gt_scaled_env = lmdb.open(dataroot_uvd_gt_scaled, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "uvd_gt = pd.read_lmdb(key, uvd_gt_scaled_env, np.float32, (21, 3))\n",
    "\n",
    "dataroot_xyz_gt = os.path.join(DATA_DIR, save_prefix + '_xyz_gt.lmdb')\n",
    "xyz_gt_env = lmdb.open(dataroot_xyz_gt, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "xyz_gt = pd.read_lmdb(key, xyz_gt_env, np.float32, (21, 3))\n",
    "uvd_gt_ori = xyzuvd.xyz2uvd_color(xyz_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(os.path.join(DATASET_DIR, 'First_Person_Action_Benchmark', 'Video_files', key)))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "visual.visualize_joints_2d(ax, uvd_gt_ori[REORDER], joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(os.path.join(DATASET_DIR, 'First_Person_Action_Benchmark', 'Video_files_256_crop', key)))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "visual.visualize_joints_2d(ax, uvd_gt[REORDER], joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_kps = []\n",
    "for kps in uvd_gt:\n",
    "    skel_kps.append(ia.Keypoint(x=kps[0],y=kps[1]))\n",
    "skel_kpsoi = ia.KeypointsOnImage(skel_kps, shape=img.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "    iaa.WithChannels(0, iaa.Add((-18, 18))), #hue\n",
    "    iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\"),\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}),\n",
    "])\n",
    "\n",
    "seq_det = seq.to_deterministic()\n",
    "img_aug = seq_det.augment_images([img])[0]\n",
    "kps_aug = seq_det.augment_keypoints([skel_kpsoi])[0]\n",
    "kps_aug = kps_aug.get_coords_array()\n",
    "uvd_gt_aug = np.concatenate((kps_aug, np.expand_dims((uvd_gt[:, 2]), -1)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(DATASET_DIR, 'First_Person_Action_Benchmark', 'Video_files_256_crop', key))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_aug)\n",
    "visual.visualize_joints_2d(ax, uvd_gt_aug[REORDER], joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoremap_gt = pd.create_multiple_gaussian_map(uvd_gt_scaled, (256, 256))\n",
    "for i in range(21):\n",
    "    fig, ax = plt.subplots()\n",
    "    visual.visualize_joints_2d(ax, uvd_gt_aug[REORDER], joint_idxs=False)\n",
    "    scoremap_show = cv2.cvtColor(scoremap_gt[:, :, i],cv2.COLOR_GRAY2RGB)\n",
    "    scoremap_show = cv2.normalize(scoremap_show, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8UC3)\n",
    "    show = 0.5*scoremap_show + 0.5*img_aug\n",
    "    ax.imshow(show.astype('uint32'))\n",
    "    ax.set_title('scoremap_gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoremap_gt = pd.create_multiple_gaussian_map(uvd_gt_scaled, (256, 256))\n",
    "scoremap_gt = resize(scoremap_gt, (32, 32), order=3, preserve_range=True).astype('float32')\n",
    "img_32_aug = pd.sk_resize(img_aug, (32, 32)).astype('uint32')\n",
    "for i in range(21):\n",
    "    fig, ax = plt.subplots()\n",
    "    scoremap_show = cv2.cvtColor(scoremap_gt[:, :, i],cv2.COLOR_GRAY2RGB)\n",
    "    scoremap_show = cv2.normalize(scoremap_show, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8UC3)\n",
    "    show = 0.5*scoremap_show + 0.5*img_32_aug\n",
    "    ax.imshow(show.astype('uint32'))\n",
    "    ax.set_title('scoremap_gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
