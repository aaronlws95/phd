{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Loading utilities\n",
    "def load_objects(obj_root):\n",
    "    object_names = ['juice_bottle', 'liquid_soap', 'milk', 'salt']\n",
    "    all_models = {}\n",
    "    for obj_name in object_names:\n",
    "        obj_path = os.path.join(obj_root, '{}_model'.format(obj_name),\n",
    "                                '{}_model.ply'.format(obj_name))\n",
    "        mesh = trimesh.load(obj_path)\n",
    "        all_models[obj_name] = {\n",
    "            'verts': np.array(mesh.vertices),\n",
    "            'faces': np.array(mesh.faces)\n",
    "        }\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def get_skeleton(sample, skel_root):\n",
    "    skeleton_path = os.path.join(skel_root, sample['subject'],\n",
    "                                 sample['action_name'], sample['seq_idx'],\n",
    "                                 'skeleton.txt')\n",
    "    print('Loading skeleton from {}'.format(skeleton_path))\n",
    "    skeleton_vals = np.loadtxt(skeleton_path)\n",
    "    skeleton = skeleton_vals[:, 1:].reshape(skeleton_vals.shape[0], 21,\n",
    "                                            -1)[sample['frame_idx']]\n",
    "    return skeleton\n",
    "\n",
    "\n",
    "def get_obj_transform(sample, obj_root):\n",
    "    seq_path = os.path.join(obj_root, sample['subject'], sample['action_name'],\n",
    "                            sample['seq_idx'], 'object_pose.txt')\n",
    "    with open(seq_path, 'r') as seq_f:\n",
    "        raw_lines = seq_f.readlines()\n",
    "    raw_line = raw_lines[sample['frame_idx']]\n",
    "    line = raw_line.strip().split(' ')\n",
    "    trans_matrix = np.array(line[1:]).astype(np.float32)\n",
    "    trans_matrix = trans_matrix.reshape(4, 4).transpose()\n",
    "    print('Loading obj transform from {}'.format(seq_path))\n",
    "    return trans_matrix\n",
    "\n",
    "\n",
    "# Display utilities\n",
    "def visualize_joints_2d(ax, joints, joint_idxs=True, links=None, alpha=1):\n",
    "    \"\"\"Draw 2d skeleton on matplotlib axis\"\"\"\n",
    "    if links is None:\n",
    "        links = [(0, 1, 2, 3, 4), (0, 5, 6, 7, 8), (0, 9, 10, 11, 12),\n",
    "                 (0, 13, 14, 15, 16), (0, 17, 18, 19, 20)]\n",
    "    # Scatter hand joints on image\n",
    "    x = joints[:, 0]\n",
    "    y = joints[:, 1]\n",
    "    ax.scatter(x, y, 1, 'r')\n",
    "\n",
    "    # Add idx labels to joints\n",
    "    for row_idx, row in enumerate(joints):\n",
    "        if joint_idxs:\n",
    "            plt.annotate(str(row_idx), (row[0], row[1]))\n",
    "    _draw2djoints(ax, joints, links, alpha=alpha)\n",
    "\n",
    "\n",
    "def _draw2djoints(ax, annots, links, alpha=1):\n",
    "    \"\"\"Draw segments, one color per link\"\"\"\n",
    "    colors = ['r', 'm', 'b', 'c', 'g']\n",
    "\n",
    "    for finger_idx, finger_links in enumerate(links):\n",
    "        for idx in range(len(finger_links) - 1):\n",
    "            _draw2dseg(\n",
    "                ax,\n",
    "                annots,\n",
    "                finger_links[idx],\n",
    "                finger_links[idx + 1],\n",
    "                c=colors[finger_idx],\n",
    "                alpha=alpha)\n",
    "\n",
    "\n",
    "def _draw2dseg(ax, annot, idx1, idx2, c='r', alpha=1):\n",
    "    \"\"\"Draw segment of given color\"\"\"\n",
    "    ax.plot(\n",
    "        [annot[idx1, 0], annot[idx2, 0]], [annot[idx1, 1], annot[idx2, 1]],\n",
    "        c=c,\n",
    "        alpha=alpha)\n",
    "    \n",
    "def get_data_list(modality, dataset_dir):\n",
    "    train_pairs = []\n",
    "    test_pairs = []\n",
    "    img_dir = os.path.join(dataset_dir, 'Video_files')\n",
    "    skel_dir = os.path.join(dataset_dir, 'Hand_pose_annotation_v1')\n",
    "    if modality == 'depth':\n",
    "        img_type = 'png'\n",
    "    else:\n",
    "        img_type = 'jpeg'\n",
    "    with open(os.path.join(dataset_dir, 'data_split_action_recognition.txt')) as f:\n",
    "        cur_split = 'Training'\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            words = l.split()\n",
    "            if(words[0] == 'Training' or words[0] == 'Test'):\n",
    "                cur_split = words[0]\n",
    "            else:\n",
    "                path = l.split()[0]\n",
    "                full_path = os.path.join(img_dir, path, modality)\n",
    "                len_frame_idx = len([x for x in os.listdir(full_path)\n",
    "                                    if os.path.join(full_path, x)])\n",
    "                skeleton_path = os.path.join(skel_dir, path, 'skeleton.txt')\n",
    "                skeleton_vals = np.loadtxt(skeleton_path)\n",
    "                for i in range(len_frame_idx):\n",
    "                    img_path = os.path.join(img_dir, path, modality, '%s_%04d.%s' %(modality, i, img_type))\n",
    "                    skel_xyz = skeleton_vals[:, 1:].reshape(skeleton_vals.shape[0], -1)[i]\n",
    "                    data_pair = (img_path, skel_xyz)\n",
    "                    if cur_split == 'Training':\n",
    "                        train_pairs.append(data_pair)\n",
    "                    else:\n",
    "                        test_pairs.append(data_pair)\n",
    "    return train_pairs, test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/4TB/aaron/First_Person_Action_Benchmark'\n",
    "train_pairs, test_pairs = get_data_list('color', root)\n",
    "file_name = [i for i,j in train_pairs]\n",
    "train_file_name = [file.split('/') for file in file_name]\n",
    "file_name = [i for i,j in test_pairs]\n",
    "test_file_name = [file.split('/') for file in file_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--root', required=True, help='Path to dataset install')\n",
    "# parser.add_argument('--subject', required=True, default='Subject_1')\n",
    "# parser.add_argument('--action_name', required=True, default='open_liquid_soap')\n",
    "# parser.add_argument('--seq_idx', required=True, default='1')\n",
    "# parser.add_argument('--frame_idx', required=True, default=0, type=int)\n",
    "# parser.add_argument(\n",
    "#     '--obj', required=True, choices=['liquid_soap', 'juice_bottle', 'milk', 'salt'])\n",
    "# args = parser.parse_args()\n",
    "reorder_idx = np.array([\n",
    "    0, 1, 6, 7, 8, 2, 9, 10, 11, 3, 12, 13, 14, 4, 15, 16, 17, 5, 18, 19,\n",
    "    20\n",
    "])\n",
    "\n",
    "file_name = train_file_name\n",
    "print(len(file_name))\n",
    "\n",
    "\n",
    "# root = '/4TB/aaron/First_Person_Action_Benchmark'\n",
    "# subject = 'Subject_1'\n",
    "# action_name = 'open_liquid_soap'\n",
    "# seq_idx = '1'\n",
    "# frame_idx = 0\n",
    "idx = 34110                 \n",
    "subject = file_name[idx][5]\n",
    "action_name = file_name[idx][6]\n",
    "seq_idx = file_name[idx][7]\n",
    "frame_idx = int(file_name[idx][-1][-9:-5])\n",
    "\n",
    "# obj = 'liquid_soap'\n",
    "obj = None\n",
    "sample = {\n",
    "    'subject': subject,\n",
    "    'action_name': action_name,\n",
    "    'seq_idx': seq_idx,\n",
    "    'frame_idx': frame_idx,\n",
    "    'object': obj\n",
    "}\n",
    "\n",
    "print('Loading sample {}'.format(sample))\n",
    "cam_extr = np.array(\n",
    "    [[0.999988496304, -0.00468848412856, 0.000982563360594,\n",
    "      25.7], [0.00469115935266, 0.999985218048, -0.00273845880292, 1.22],\n",
    "     [-0.000969709653873, 0.00274303671904, 0.99999576807,\n",
    "      3.902], [0, 0, 0, 1]])\n",
    "cam_intr = np.array([[1395.749023, 0, 935.732544],\n",
    "                     [0, 1395.749268, 540.681030], [0, 0, 1]])\n",
    "cam_intr_depth = [[475.065948, 0,  315.944855],\n",
    "                  [0, 475.065857, 245.287079],\n",
    "                  [0, 0, 1]]\n",
    "\n",
    "\n",
    "skeleton_root = os.path.join(root, 'Hand_pose_annotation_v1')\n",
    "obj_root = os.path.join(root, 'Object_models')\n",
    "obj_trans_root = os.path.join(root, 'Object_6D_pose_annotation_v1')\n",
    "skel = get_skeleton(sample, skeleton_root)[reorder_idx]\n",
    "\n",
    "# Apply camera extrinsic to hand skeleton\n",
    "skel_hom = np.concatenate([skel, np.ones([skel.shape[0], 1])], 1)\n",
    "skel_camcoords = cam_extr.dot(\n",
    "    skel_hom.transpose()).transpose()[:, :3].astype(np.float32)\n",
    "\n",
    "skel_hom2d = np.array(cam_intr).dot(skel_camcoords.transpose()).transpose()\n",
    "skel_proj = (skel_hom2d / skel_hom2d[:, 2:])[:, :2]\n",
    "\n",
    "# Plot everything\n",
    "# Load image and display\n",
    "# ax = fig.add_subplot(221)\n",
    "img_path = os.path.join(root, 'Video_files', sample['subject'],\n",
    "                        sample['action_name'], sample['seq_idx'], 'color',\n",
    "                        'color_{:04d}.jpeg'.format(sample['frame_idx']))\n",
    "print('Loading image from {}'.format(img_path))\n",
    "img = Image.open(img_path)\n",
    "# ax.imshow(img)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax[0].imshow(img)\n",
    "visualize_joints_2d(ax[0], skel_proj, joint_idxs=False)\n",
    "\n",
    "skel_hom2d = np.array(cam_intr_depth).dot(skel.transpose()).transpose()\n",
    "skel_proj = (skel_hom2d / skel_hom2d[:, 2:])[:, :2]\n",
    "\n",
    "# Plot everything\n",
    "# Load image and display\n",
    "# ax = fig.add_subplot(221)\n",
    "img_path = os.path.join(root, 'Video_files', sample['subject'],\n",
    "                        sample['action_name'], sample['seq_idx'], 'depth',\n",
    "                        'depth_{:04d}.png'.format(sample['frame_idx']))\n",
    "print('Loading image from {}'.format(img_path))\n",
    "img = Image.open(img_path)\n",
    "# ax.imshow(img)\n",
    "\n",
    "ax[1].imshow(img)\n",
    "visualize_joints_2d(ax[1], skel_proj, joint_idxs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
