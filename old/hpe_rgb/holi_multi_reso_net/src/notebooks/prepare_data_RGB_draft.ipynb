{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "import utils.prepare_data as pd\n",
    "import utils.visualize as visual\n",
    "import utils.convert_xyz_uvd as xyzuvd\n",
    "import utils.camera_info as cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/aaron/SHAREDDATA/First_Person_Action_Benchmark/data_split_action_recognition.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-60032b865b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/media/aaron/SHAREDDATA/First_Person_Action_Benchmark'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/media/aaron/SHAREDDATA/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fpha_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hpe_rgb/holi_multi_reso_net/src/utils/prepare_data.py\u001b[0m in \u001b[0;36mget_fpha_data_list\u001b[0;34m(modality, dataset_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_split_action_recognition.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcur_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/aaron/SHAREDDATA/First_Person_Action_Benchmark/data_split_action_recognition.txt'"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/media/aaron/SHAREDDATA/First_Person_Action_Benchmark'\n",
    "save_dir = '/media/aaron/SHAREDDATA/data'\n",
    "train_pairs, test_pairs = pd.get_fpha_data_list('color', dataset_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [i for i,j in train_pairs]\n",
    "xyz_gt = [j for i,j in train_pairs]\n",
    "idx = 8365\n",
    "frame = file_name[idx]\n",
    "xyz_gt = np.reshape(xyz_gt, (-1, 21, 3))\n",
    "xyz_gt = xyz_gt[idx]\n",
    "uvd_gt = xyzuvd.xyz2uvd_color(xyz_gt)\n",
    "color = Image.open(frame)\n",
    "color = np.asarray(color, dtype='uint32')\n",
    "print(color.shape)\n",
    "print(frame)\n",
    "\n",
    "pad = 50\n",
    "x_max = int(np.amax(uvd_gt[:,0])) + pad\n",
    "x_min = np.maximum(int(np.amin(uvd_gt[:,0])) - pad, 0)\n",
    "y_max = int(np.amax(uvd_gt[:,1])) + pad\n",
    "y_min = np.maximum(int(np.amin(uvd_gt[:,1])) - pad, 0)\n",
    "print(x_max, x_min, y_max, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.show_img_and_skel_color(frame, uvd_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_frame_96 = resize(color, (96, 96), order=3, preserve_range=True)\n",
    "crop_frame_96 = np.asarray(crop_frame_96, dtype='uint32')\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(crop_frame_96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_joint_idx = 3\n",
    "ref_z = 1000\n",
    "bbsize = 260 #124x124 bbox in uvd\n",
    "img_size = 96\n",
    "u0 = cam.X0_COLOR\n",
    "v0 = cam.Y0_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bbox_uvd = xyzuvd.get_bbox(bbsize, ref_z, u0, v0)\n",
    "print(bbox_uvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_max = np.amax(uvd_gt[:,0])\n",
    "# x_min = np.amin(uvd_gt[:,0])\n",
    "# y_max = np.amax(uvd_gt[:,1])\n",
    "# y_min = np.amin(uvd_gt[:,1])\n",
    "# z_max = np.amax(uvd_gt[:,2])\n",
    "# z_min = np.amin(uvd_gt[:,2])\n",
    "\n",
    "# print(x_max, x_min, y_max, y_min, z_max, z_min)\n",
    "\n",
    "# pad = 50\n",
    "# x_max = int(x_max) + pad\n",
    "# x_min = int(x_min) - pad\n",
    "# y_max = int(y_max) + pad\n",
    "# y_min = int(y_min) - pad\n",
    "# z_max = int(z_max)\n",
    "# z_min = int(z_min)\n",
    "# print(x_max, x_min, y_max, y_min, z_max, z_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.shape)\n",
    "crop_color = color[y_min:y_max, x_min:x_max, :]\n",
    "print(crop_color)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(crop_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_hand_gt = xyz_gt.copy()\n",
    "mean_z = xyz_hand_gt[center_joint_idx, 2]\n",
    "xyz_hand_gt[:,2] += ref_z - mean_z\n",
    "uvd_hand_gt = xyzuvd.xyz2uvd_color(xyz_hand_gt)\n",
    "mean_u = uvd_hand_gt[center_joint_idx, 0]\n",
    "mean_v = uvd_hand_gt[center_joint_idx, 1]\n",
    "\n",
    "_, bbox_uvd = xyzuvd.get_bbox(bbsize, ref_z, u0, v0)\n",
    "\n",
    "uvd_hand_gt[:,0] = (uvd_hand_gt[:,0] - mean_u + bbox_uvd[0,0]/2 ) / bbox_uvd[0,0]\n",
    "uvd_hand_gt[np.where(uvd_hand_gt[:,0]>1),0]=1\n",
    "uvd_hand_gt[np.where(uvd_hand_gt[:,0]<0),0]=0\n",
    "\n",
    "uvd_hand_gt[:,1] =(uvd_hand_gt[:,1] - mean_v+bbox_uvd[0,1]/2) / bbox_uvd[0,1]\n",
    "uvd_hand_gt[ np.where(uvd_hand_gt[:,1]>1),1]=1\n",
    "uvd_hand_gt[ np.where(uvd_hand_gt[:,1]<0),1]=0\n",
    "\n",
    "uvd_hand_gt[:,2] = (uvd_hand_gt[:,2] - ref_z + bbsize/2)/bbsize\n",
    "\n",
    "print(mean_u, mean_v, mean_z)\n",
    "print(bbox_uvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/media/aaron/SHAREDDATA/First_Person_Action_Benchmark'\n",
    "save_dir = '/media/aaron/SHAREDDATA/data'\n",
    "train_pairs, test_pairs = pd.get_fpha_data_list('color', dataset_dir)\n",
    "file_name = [i for i,j in train_pairs]\n",
    "xyz_gt = [j for i,j in train_pairs]\n",
    "idx = 8360\n",
    "frame = file_name[idx]\n",
    "\n",
    "# center_joint_idx = 3\n",
    "# ref_z = 1000\n",
    "# bbsize = 260 #124x124 bbox in uvd\n",
    "# img_size = 96\n",
    "# u0 = cam.X0_COLOR\n",
    "# v0 = cam.Y0_COLOR\n",
    "\n",
    "# #to save\n",
    "# new_file_name=[]\n",
    "# uvd_norm_gt=[]\n",
    "# hand_center_uvd=[]\n",
    "# r0=[]\n",
    "# r1=[]\n",
    "# r2=[]\n",
    "\n",
    "# xyz_gt = np.reshape(xyz_gt, (-1, 21, 3))\n",
    "# uvd_gt = xyzuvd.xyz2uvd_color(xyz_gt)\n",
    "\n",
    "# i = 2175\n",
    "# color = Image.open(file_name[i])\n",
    "# color = np.asarray(color, dtype='uint16')\n",
    "\n",
    "# #collect the points within the axis-aligned BBOX of the hand\n",
    "# xyz_hand_gt = xyz_gt[i].copy()\n",
    "# uvd_hand_gt = uvd_gt[i].copy()\n",
    "\n",
    "# pad = 50\n",
    "# x_max = int(np.amax(uvd_hand_gt[:,0])) + pad\n",
    "# x_min = int(np.amin(uvd_hand_gt[:,0])) - pad\n",
    "# y_max = int(np.amax(uvd_hand_gt[:,1])) + pad\n",
    "# y_min = int(np.amin(uvd_hand_gt[:,1])) - pad\n",
    "\n",
    "# crop_hand = color[y_min:y_max, x_min:x_max, :]\n",
    "\n",
    "# _, bbox_uvd = xyzuvd.get_bbox(bbsize, ref_z, u0, v0)\n",
    "\n",
    "# #mean calculation\n",
    "# mean_z = xyz_hand_gt[center_joint_idx, 2]\n",
    "# xyz_hand_gt[:,2] += ref_z - mean_z\n",
    "# uvd_hand_gt = xyzuvd.xyz2uvd_color(xyz_hand_gt)\n",
    "# mean_u = uvd_hand_gt[center_joint_idx, 0]\n",
    "# mean_v = uvd_hand_gt[center_joint_idx, 1]\n",
    "\n",
    "# #U\n",
    "# uvd_hand_gt[:,0] = (uvd_hand_gt[:,0] - mean_u + bbox_uvd[0,0]/2 ) / bbox_uvd[0,0]\n",
    "# uvd_hand_gt[np.where(uvd_hand_gt[:,0]>1),0]=1\n",
    "# uvd_hand_gt[np.where(uvd_hand_gt[:,0]<0),0]=0\n",
    "\n",
    "# #V\n",
    "# uvd_hand_gt[:,1] =(uvd_hand_gt[:,1] - mean_v+bbox_uvd[0,1]/2) / bbox_uvd[0,1]\n",
    "# uvd_hand_gt[ np.where(uvd_hand_gt[:,1]>1),1]=1\n",
    "# uvd_hand_gt[ np.where(uvd_hand_gt[:,1]<0),1]=0\n",
    "\n",
    "# # Z\n",
    "# uvd_hand_gt[:,2] = (uvd_hand_gt[:,2] - ref_z + bbsize/2)/bbsize\n",
    "\n",
    "# r0_i = resize(crop_hand, (img_size, img_size), order=3, preserve_range=True)\n",
    "# r1_i = resize(crop_hand, (img_size/2, img_size/2), order=3, preserve_range=True)\n",
    "# r2_i = resize(crop_hand, (img_size/4, img_size/4), order=3, preserve_range=True)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(r0_i.astype('uint32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
