{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from utils.directory import DATA_DIR, DATASET_DIR\n",
    "import utils.prepare_data as pd\n",
    "import utils.error as error\n",
    "import utils.visualize as visual\n",
    "import utils.convert_xyz_uvd as xyzuvd\n",
    "# jupyter nbconvert --to html evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_pose = 100\n",
    "epoch_pose = 150\n",
    "exp_pose = 'pose_net_aug'\n",
    "from_pred_smap = True\n",
    "\n",
    "# epoch = 265\n",
    "epoch = 340\n",
    "exp = 'base_lift_net'\n",
    "\n",
    "data_split = 'train'\n",
    "save_prefix = 'train_fpha'\n",
    "keys_cache_file = os.path.join(DATA_DIR, save_prefix + '_keys_cache.p')\n",
    "train_keys = pickle.load(open(keys_cache_file, \"rb\"))\n",
    "\n",
    "dataroot_xyz_gt_saved = os.path.join(DATA_DIR, save_prefix + '_xyz_gt.lmdb')\n",
    "\n",
    "train_xyz_gt = pd.read_all_lmdb_from_file(train_keys, dataroot_xyz_gt_saved, np.float32, (21, 3))\n",
    "train_xyz_gt = np.asarray(train_xyz_gt)\n",
    "train_uvd_gt = xyzuvd.xyz2uvd_color(train_xyz_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot_xyz_gt_canon = os.path.join(DATA_DIR, save_prefix + '_xyz_gt_canon.lmdb')\n",
    "dataroot_rot_mat = os.path.join(DATA_DIR, save_prefix + '_rot_mat.lmdb')\n",
    "train_xyz_gt_canon = pd.read_all_lmdb_from_file(train_keys, dataroot_xyz_gt_canon, np.float32, (21, 3))\n",
    "train_rot_mat = pd.read_all_lmdb_from_file(train_keys, dataroot_rot_mat, np.float32, (3, 3))\n",
    "\n",
    "if from_pred_smap:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'xyz_canon_%s_%s_smap_%s_%s.txt' %(epoch, data_split, epoch_pose, exp_pose))\n",
    "else:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'xyz_canon_%s_%s.txt' %(epoch, data_split))\n",
    "train_pred_xyz_canon = pd.get_pred_xyz_canon(pred_file, save_prefix)\n",
    "if from_pred_smap:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'rot_mat_%s_%s_smap_%s_%s.txt' %(epoch, data_split, epoch_pose, exp_pose))\n",
    "else:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'rot_mat_%s_%s.txt' %(epoch, data_split))\n",
    "train_rot_mat_pred = pd.get_pred_rot_mat(pred_file, save_prefix)\n",
    "\n",
    "keypoint_scale = pd.get_keypoint_scale(train_xyz_gt)\n",
    "\n",
    "train_pred_xyz = []\n",
    "for canon, rot, scale in zip(train_pred_xyz_canon, train_rot_mat_pred, keypoint_scale):\n",
    "    train_pred_xyz.append(np.matmul(canon, rot)*scale)\n",
    "\n",
    "train_pred_xyz += np.expand_dims(train_xyz_gt[:, 0, :], axis=1)\n",
    "train_pred_xyz = np.asarray(train_pred_xyz).astype(np.float32)\n",
    "train_pred_uvd = xyzuvd.xyz2uvd_color(np.asarray(train_pred_xyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 'test'\n",
    "save_prefix = 'test_fpha'\n",
    "keys_cache_file = os.path.join(DATA_DIR, save_prefix + '_keys_cache.p')\n",
    "test_keys = pickle.load(open(keys_cache_file, \"rb\"))\n",
    "\n",
    "dataroot_xyz_gt_saved = os.path.join(DATA_DIR, save_prefix + '_xyz_gt.lmdb')\n",
    "\n",
    "test_xyz_gt = pd.read_all_lmdb_from_file(test_keys, dataroot_xyz_gt_saved, np.float32, (21, 3))\n",
    "test_xyz_gt = np.asarray(test_xyz_gt)\n",
    "test_uvd_gt = xyzuvd.xyz2uvd_color(test_xyz_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot_xyz_gt_canon = os.path.join(DATA_DIR, save_prefix + '_xyz_gt_canon.lmdb')\n",
    "dataroot_rot_mat = os.path.join(DATA_DIR, save_prefix + '_rot_mat.lmdb')\n",
    "test_xyz_gt_canon = pd.read_all_lmdb_from_file(test_keys, dataroot_xyz_gt_canon, np.float32, (21, 3))\n",
    "test_rot_mat = pd.read_all_lmdb_from_file(test_keys, dataroot_rot_mat, np.float32, (3, 3))\n",
    "\n",
    "if from_pred_smap:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'xyz_canon_%s_%s_smap_%s_%s.txt' %(epoch, data_split, epoch_pose, exp_pose))\n",
    "else:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'xyz_canon_%s_%s.txt' %(epoch, data_split))\n",
    "test_pred_xyz_canon = pd.get_pred_xyz_canon(pred_file, save_prefix)\n",
    "if from_pred_smap:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'rot_mat_%s_%s_smap_%s_%s.txt' %(epoch, data_split, epoch_pose, exp_pose))\n",
    "else:\n",
    "    pred_file = os.path.join(DATA_DIR, exp, 'rot_mat_%s_%s.txt' %(epoch, data_split))\n",
    "test_rot_mat_pred = pd.get_pred_rot_mat(pred_file, save_prefix)\n",
    "\n",
    "keypoint_scale = pd.get_keypoint_scale(test_xyz_gt)\n",
    "\n",
    "test_pred_xyz = []\n",
    "for canon, rot, scale in zip(test_pred_xyz_canon, test_rot_mat_pred, keypoint_scale):\n",
    "    test_pred_xyz.append(np.matmul(canon, rot)*scale)\n",
    "\n",
    "test_pred_xyz += np.expand_dims(test_xyz_gt[:, 0, :], axis=1)\n",
    "test_pred_xyz = np.asarray(test_pred_xyz).astype(np.float32)\n",
    "test_pred_uvd = xyzuvd.xyz2uvd_color(np.asarray(test_pred_xyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = train_xyz_gt_canon\n",
    "true = train_pred_xyz_canon\n",
    "print('TRAIN mean_l2_error CANON: ', error.mean_pose_error(true, pred))\n",
    "\n",
    "pred = np.asarray(train_rot_mat_pred)\n",
    "true = np.asarray(train_rot_mat)\n",
    "errorrm = np.mean((true-pred)**2)\n",
    "print('TRAIN mean_l2_error ROT MAT: ', errorrm)\n",
    "\n",
    "pred = test_xyz_gt_canon\n",
    "true = test_pred_xyz_canon\n",
    "print('TEST mean_l2_error CANON: ', error.mean_pose_error(true, pred))\n",
    "\n",
    "pred = np.asarray(test_rot_mat_pred)\n",
    "true = np.asarray(test_rot_mat)\n",
    "errorrm = np.mean((true-pred)**2)\n",
    "print('TEST mean_l2_error ROT MAT: ', errorrm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_frame = 'uvd'\n",
    "pred = train_pred_uvd\n",
    "true = train_uvd_gt\n",
    "print('%s TRAIN mean_l2_error: ' %coord_frame, error.mean_pose_error(true, pred))\n",
    "pred = test_pred_uvd\n",
    "true = test_uvd_gt\n",
    "print('%s TEST mean_l2_error: ' %coord_frame, error.mean_pose_error(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_frame = 'xyz'\n",
    "pred = train_pred_xyz\n",
    "true = train_xyz_gt\n",
    "print('%s TRAIN mean_l2_error: ' %coord_frame, error.mean_pose_error(true, pred))\n",
    "pred = test_pred_xyz\n",
    "true = test_xyz_gt\n",
    "print('%s TEST mean_l2_error: ' %coord_frame, error.mean_pose_error(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of correct key points\n",
    "pred = train_pred_xyz\n",
    "true = train_xyz_gt\n",
    "pck = error.percentage_frames_within_error_curve_zimmmerman(true, pred)\n",
    "print(pck)\n",
    "thresholds = np.arange(0, 85, 5)\n",
    "print('AUC:', error.calc_auc(pck, thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of correct key points\n",
    "pred = test_pred_xyz\n",
    "true = test_xyz_gt\n",
    "pck = error.percentage_frames_within_error_curve_zimmmerman(true, pred)\n",
    "print('[', end =\" \")\n",
    "for num in pck:\n",
    "    print('%f, ' %num, end =\" \")\n",
    "print(']')\n",
    "thresholds = np.arange(0, 85, 5)\n",
    "print('AUC:', error.calc_auc(pck, thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1659\n",
    "file_name = os.path.join(DATASET_DIR, 'First_Person_Action_Benchmark', 'Video_files', test_keys[idx])\n",
    "visual.show_true_pred_img_and_skel_color(file_name, test_uvd_gt[idx], test_pred_uvd[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(DATASET_DIR, 'First_Person_Action_Benchmark', 'Video_files', train_keys[idx])\n",
    "visual.show_true_pred_img_and_skel_color(file_name, train_uvd_gt[idx], train_pred_uvd[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
